{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0619c293",
   "metadata": {},
   "source": [
    "newbie practice with shadowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "590c1442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIENCED MODE: press 'q' to quit.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pickleball - Newbie (guided shadowing) + Experienced (visualize) modes\n",
    "\n",
    "How to use:\n",
    "- Run the script.\n",
    "- Type 'newbie' or 'experienced' when prompted.\n",
    "- In newbie mode you'll be asked which pose and handedness to train.\n",
    "- Press 'q' to quit, 'r' to reset progress, 'h' to toggle handedness, 'n' to switch to next pose.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# -------------------------\n",
    "# MediaPipe pose init\n",
    "# -------------------------\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "POSE = mp_pose.Pose(static_image_mode=False,\n",
    "                    model_complexity=1,\n",
    "                    min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "# -------------------------\n",
    "# Utility helpers\n",
    "# -------------------------\n",
    "def lm_xy_px(landmarks, lm_enum, w, h, vis_thresh=0.25):\n",
    "    \"\"\"\n",
    "    Convert a MediaPipe landmark enum to pixel (x, y).\n",
    "    Returns None if the landmark is missing or has low visibility.\n",
    "    \"\"\"\n",
    "    idx = lm_enum.value\n",
    "    lm = landmarks[idx]\n",
    "    if hasattr(lm, \"visibility\") and lm.visibility is not None and lm.visibility < vis_thresh:\n",
    "        return None\n",
    "    # landmark coordinates are normalized [0..1]\n",
    "    return int(lm.x * w), int(lm.y * h)\n",
    "\n",
    "def vec(a, b):\n",
    "    \"\"\"Return vector from a to b (b - a).\"\"\"\n",
    "    return np.array([b[0]-a[0], b[1]-a[1]], dtype=np.float32)\n",
    "\n",
    "def norm(v):\n",
    "    \"\"\"L2 norm with safe fallback.\"\"\"\n",
    "    v = np.array(v, dtype=np.float32)\n",
    "    n = np.linalg.norm(v)\n",
    "    if n < 1e-6:\n",
    "        return v, 1e-6\n",
    "    return v / n, n\n",
    "\n",
    "# -------------------------\n",
    "# Compute dynamic guide points\n",
    "# -------------------------\n",
    "def compute_guide_points(landmarks, frame_w, frame_h, pose_name=\"serve\", handedness=\"right\"):\n",
    "    \"\"\"\n",
    "    Compute 3 guide (x,y) points in pixels for the selected pose based on the player's body.\n",
    "    - landmarks: MediaPipe landmarks list\n",
    "    - frame_w/frame_h: frame size in pixels\n",
    "    - pose_name: 'serve', 'forehand', 'backhand'\n",
    "    - handedness: 'right' or 'left'\n",
    "    Returns: list of 3 (x,y) tuples. If landmarks insufficient, returns fallback centered points.\n",
    "    \"\"\"\n",
    "    # get core landmarks (may return None)\n",
    "    nose = lm_xy_px(landmarks, mp_pose.PoseLandmark.NOSE, frame_w, frame_h)\n",
    "    ls = lm_xy_px(landmarks, mp_pose.PoseLandmark.LEFT_SHOULDER, frame_w, frame_h)\n",
    "    rs = lm_xy_px(landmarks, mp_pose.PoseLandmark.RIGHT_SHOULDER, frame_w, frame_h)\n",
    "    lh = lm_xy_px(landmarks, mp_pose.PoseLandmark.LEFT_HIP, frame_w, frame_h)\n",
    "    rh = lm_xy_px(landmarks, mp_pose.PoseLandmark.RIGHT_HIP, frame_w, frame_h)\n",
    "    lw = lm_xy_px(landmarks, mp_pose.PoseLandmark.LEFT_WRIST, frame_w, frame_h)\n",
    "    rw = lm_xy_px(landmarks, mp_pose.PoseLandmark.RIGHT_WRIST, frame_w, frame_h)\n",
    "\n",
    "    # if required landmarks are missing, provide safe fallback: center three vertical points\n",
    "    if ls is None or rs is None or lh is None or rh is None:\n",
    "        cx, cy = frame_w // 2, frame_h // 2\n",
    "        return [(cx, int(cy*0.4)), (cx, cy), (cx, int(cy*1.4))]\n",
    "\n",
    "    # compute body center/axes\n",
    "    shoulder_center = ((ls[0] + rs[0]) / 2.0, (ls[1] + rs[1]) / 2.0)\n",
    "    hip_center = ((lh[0] + rh[0]) / 2.0, (lh[1] + rh[1]) / 2.0)\n",
    "    # horizontal axis (shoulder left -> right)\n",
    "    horiz_vec_raw = vec(ls, rs)\n",
    "    horiz_unit, shoulder_width = norm(horiz_vec_raw)\n",
    "    # vertical axis (hip -> shoulder)\n",
    "    up_vec_raw = vec(hip_center, shoulder_center)\n",
    "    up_unit, body_height = norm(up_vec_raw)\n",
    "    # dominant side\n",
    "    side = 1 if handedness.lower().startswith(\"r\") else -1\n",
    "\n",
    "    # some scale constants tuned by heuristics\n",
    "    w_factor = max(1.0, shoulder_width)  # shoulder width as pixels\n",
    "    h_factor = max(1.0, body_height)\n",
    "\n",
    "    # Serve: toss → contact → follow-through (roughly vertical toss + forward contact)\n",
    "    if pose_name.lower().startswith(\"serve\"):\n",
    "        # toss: above head ~ shoulder_center + up * (body_height * 1.0)\n",
    "        toss = (int(shoulder_center[0] + up_unit[0] * h_factor * 0.9),\n",
    "                int(shoulder_center[1] + up_unit[1] * h_factor * 0.9))\n",
    "        # contact: forward and slightly up from shoulder on dominant side\n",
    "        contact = (int(shoulder_center[0] + horiz_unit[0] * (side * 0.7 * w_factor) + up_unit[0] * (-0.15 * h_factor)),\n",
    "                   int(shoulder_center[1] + horiz_unit[1] * (side * 0.7 * w_factor) + up_unit[1] * (-0.15 * h_factor)))\n",
    "        # follow: across body (opposite shoulder area)\n",
    "        follow = (int(shoulder_center[0] + horiz_unit[0] * (side * -0.35 * w_factor) + up_unit[0] * (0.2 * h_factor)),\n",
    "                  int(shoulder_center[1] + horiz_unit[1] * (side * -0.35 * w_factor) + up_unit[1] * (0.2 * h_factor)))\n",
    "        return [toss, contact, follow]\n",
    "\n",
    "    # Forehand: start (back), contact (front/shoulder), follow (across)\n",
    "    if pose_name.lower().startswith(\"fore\"):\n",
    "        # start: slightly behind hip on dominant side\n",
    "        start = (int(hip_center[0] + horiz_unit[0] * (side * 0.2 * w_factor) + up_unit[0] * (0.05 * h_factor)),\n",
    "                 int(hip_center[1] + horiz_unit[1] * (side * 0.2 * w_factor) + up_unit[1] * (0.05 * h_factor)))\n",
    "        # contact: in front of shoulder\n",
    "        contact = (int(shoulder_center[0] + horiz_unit[0] * (side * 0.55 * w_factor)),\n",
    "                   int(shoulder_center[1] + horiz_unit[1] * (side * 0.55 * w_factor)))\n",
    "        # follow: across torso, slightly lower\n",
    "        follow = (int(shoulder_center[0] + horiz_unit[0] * (side * -0.25 * w_factor) + up_unit[0] * (0.15 * h_factor)),\n",
    "                  int(shoulder_center[1] + horiz_unit[1] * (side * -0.25 * w_factor) + up_unit[1] * (0.15 * h_factor)))\n",
    "        return [start, contact, follow]\n",
    "\n",
    "    # Backhand: mirror of forehand (dominant side considered above)\n",
    "    if pose_name.lower().startswith(\"back\"):\n",
    "        # start: slightly behind hip on dominant side\n",
    "        start = (int(hip_center[0] + horiz_unit[0] * (side * -0.2 * w_factor) + up_unit[0] * (0.05 * h_factor)),\n",
    "                 int(hip_center[1] + horiz_unit[1] * (side * -0.2 * w_factor) + up_unit[1] * (0.05 * h_factor)))\n",
    "        # contact: in front of shoulder (but for backhand across body)\n",
    "        contact = (int(shoulder_center[0] + horiz_unit[0] * (side * -0.45 * w_factor)),\n",
    "                   int(shoulder_center[1] + horiz_unit[1] * (side * -0.45 * w_factor)))\n",
    "        # follow: across body\n",
    "        follow = (int(shoulder_center[0] + horiz_unit[0] * (side * 0.3 * w_factor) + up_unit[0] * (0.12 * h_factor)),\n",
    "                  int(shoulder_center[1] + horiz_unit[1] * (side * 0.3 * w_factor) + up_unit[1] * (0.12 * h_factor)))\n",
    "        return [start, contact, follow]\n",
    "\n",
    "    # default fallback if unknown pose\n",
    "    cx, cy = frame_w // 2, frame_h // 2\n",
    "    return [(cx, int(cy*0.4)), (cx, cy), (cx, int(cy*1.4))]\n",
    "\n",
    "# -------------------------\n",
    "# Newbie mode: guided shadowing\n",
    "# -------------------------\n",
    "def newbie_mode(camera_index=0):\n",
    "    \"\"\"\n",
    "    Runs the interactive newbie trainer:\n",
    "    - User selects pose and handedness.\n",
    "    - The script computes three body-relative guide points and displays them.\n",
    "    - The user moves their dominant wrist to hit each point in order.\n",
    "    Controls:\n",
    "    - q: quit\n",
    "    - r: reset progress\n",
    "    - n: next pose\n",
    "    - h: toggle handedness\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(camera_index)\n",
    "    if not cap.isOpened():\n",
    "        print(\"ERROR: Camera not available.\")\n",
    "        return\n",
    "\n",
    "    pose_choices = [\"serve\", \"forehand\", \"backhand\"]\n",
    "    choice_idx = 0\n",
    "    handedness = \"right\"  # default; user can toggle with 'h'\n",
    "    progress = 0\n",
    "    hit_cooldown = 0.4  # seconds freeze after hitting a point so user can prepare\n",
    "    last_hit_time = 0.0\n",
    "    radius = 18  # visual radius of guide point\n",
    "    dist_thresh_px = 60  # how close wrist must be to count as hit (pixels) - adjust per camera\n",
    "\n",
    "    print(\"NEWBIE MODE: press 'q' to quit, 'r' to reset, 'n' next pose, 'h' toggle hand\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        h, w, _ = frame.shape\n",
    "\n",
    "        # run mediapipe\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = POSE.process(img_rgb)\n",
    "\n",
    "        # compute guide points (dynamic) if we have landmarks\n",
    "        guide_points = None\n",
    "        if results.pose_landmarks:\n",
    "            guide_points = compute_guide_points(results.pose_landmarks.landmark, w, h,\n",
    "                                                pose_name=pose_choices[choice_idx],\n",
    "                                                handedness=handedness)\n",
    "\n",
    "        # draw guide points (use grey if not yet active, green if passed)\n",
    "        for i, gp in enumerate(guide_points if guide_points is not None else []):\n",
    "            color = (50, 50, 50)\n",
    "            if i < progress:\n",
    "                color = (0, 200, 0)\n",
    "            elif i == progress:\n",
    "                color = (0, 255, 255)\n",
    "            cv2.circle(frame, gp, radius, color, -1)\n",
    "            cv2.putText(frame, f\"{i+1}\", (gp[0]-8, gp[1]+6), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n",
    "\n",
    "        # draw wrist tracker and check proximity\n",
    "        wrist = None\n",
    "        if results.pose_landmarks:\n",
    "            # choose dominant wrist\n",
    "            if handedness == \"right\":\n",
    "                wrist = lm_xy_px(results.pose_landmarks.landmark, mp_pose.PoseLandmark.RIGHT_WRIST, w, h)\n",
    "            else:\n",
    "                wrist = lm_xy_px(results.pose_landmarks.landmark, mp_pose.PoseLandmark.LEFT_WRIST, w, h)\n",
    "            if wrist is not None:\n",
    "                cv2.circle(frame, wrist, 10, (255, 255, 0), -1)\n",
    "\n",
    "                # proximity detection (only if we have guide points and cooldown elapsed)\n",
    "                if guide_points is not None and progress < len(guide_points) and (time.time() - last_hit_time) > hit_cooldown:\n",
    "                    tx, ty = guide_points[progress]\n",
    "                    d = np.linalg.norm(np.array(wrist, dtype=np.float32) - np.array([tx, ty], dtype=np.float32))\n",
    "                    # scale threshold by shoulder width if possible (improve robustness)\n",
    "                    # using a crude fallback if shoulder width not available\n",
    "                    if d < dist_thresh_px:\n",
    "                        progress += 1\n",
    "                        last_hit_time = time.time()\n",
    "\n",
    "        # Completion message\n",
    "        if progress >= 3:\n",
    "            cv2.putText(frame, f\"{pose_choices[choice_idx].upper()} COMPLETE!\", (30, 80),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.4, (0,255,0), 3)\n",
    "\n",
    "        # UI text\n",
    "        cv2.putText(frame, f\"Mode: NEWBIE | Pose: {pose_choices[choice_idx]} | Hand: {handedness}\",\n",
    "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "        cv2.putText(frame, f\"Progress: {progress}/3 (r reset, n next, h toggle hand, q quit)\",\n",
    "                    (10, h-20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (220,220,220), 1)\n",
    "\n",
    "        # show frame\n",
    "        cv2.imshow(\"Pickleball - Newbie Trainer\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        if key == ord(\"r\"):\n",
    "            progress = 0\n",
    "            print(\"Progress reset.\")\n",
    "        if key == ord(\"n\"):\n",
    "            choice_idx = (choice_idx + 1) % len(pose_choices)\n",
    "            progress = 0\n",
    "            print(\"Switched to pose:\", pose_choices[choice_idx])\n",
    "        if key == ord(\"h\"):\n",
    "            handedness = \"left\" if handedness == \"right\" else \"right\"\n",
    "            progress = 0\n",
    "            print(\"Toggled handedness to\", handedness)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# -------------------------\n",
    "# Experienced mode (visualize / placeholder)\n",
    "# -------------------------\n",
    "def experienced_mode(camera_index=0):\n",
    "    \"\"\"\n",
    "    Simple visualization mode for experienced players.\n",
    "    Shows pose landmarks. Replace TODO with your LSTM/YOLO inference call to classify windows.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(camera_index)\n",
    "    if not cap.isOpened():\n",
    "        print(\"ERROR: Camera not available.\")\n",
    "        return\n",
    "\n",
    "    print(\"EXPERIENCED MODE: press 'q' to quit.\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = POSE.process(img_rgb)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            # TODO: If you have a trained LSTM model, extract per-frame angles or keypoints here,\n",
    "            # collect into sliding windows and call your LSTM to get predictions.\n",
    "            # Example placeholder text:\n",
    "            cv2.putText(frame, \"Inference: (load model to enable classification)\", (10,30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200,200,0), 2)\n",
    "\n",
    "        cv2.imshow(\"Pickleball - Experienced Visualizer\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# -------------------------\n",
    "# Entry\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    mode = input(\"Choose mode (newbie/experienced): \").strip().lower()\n",
    "    if mode == \"newbie\":\n",
    "        newbie_mode(camera_index=0)\n",
    "    else:\n",
    "        experienced_mode(camera_index=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
